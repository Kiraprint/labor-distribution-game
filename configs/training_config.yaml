learning_rate: 0.0003
batch_size: 64
num_epochs: 1000
gamma: 0.99
tau: 0.005
buffer_size: 100000
update_interval: 4
num_steps: 1000
ppo_clip: 0.2
entropy_coef: 0.01
value_loss_coef: 0.5
max_grad_norm: 0.5
use_gae: true
gae_lambda: 0.95
train_on_gpu: true
gpu_id: 0
transformer:
  num_layers: 4
  d_model: 128
  num_heads: 8
  dff: 512
  dropout_rate: 0.1
  max_position_encoding: 1000
  use_positional_encoding: true
  activation_function: relu
  learning_rate_schedule: true
  warmup_steps: 4000
  learning_rate_decay: 0.1
  min_learning_rate: 1e-5